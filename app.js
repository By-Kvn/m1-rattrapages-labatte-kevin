// Chargement du mod√®le Toxicity
let toxicityModel = null;
const toxicityThreshold = 0.8; // seuil de confiance

toxicity.load(toxicityThreshold).then(model => {
	toxicityModel = model;
	console.log("Mod√®le Toxicity charg√©.");
}).catch(err => {
	console.error("Erreur de chargement du mod√®le Toxicity:", err);
});


// Gestion du formulaire
document.addEventListener("DOMContentLoaded", () => {
	const form = document.getElementById("ia-form");
	const input = document.getElementById("user-input");
	const result = document.getElementById("result");

	form.addEventListener("submit", (e) => {
		e.preventDefault();
		const text = input.value.trim();
		if (!text) {
			result.textContent = "Veuillez entrer un texte.";
			return;
		}
		// Analyse du texte
	result.textContent = `Analyse Toxicity en cours...`;
		// Analyse Toxicity (asynchrone)
		if (toxicityModel) {
			toxicityModel.classify([text]).then(predictions => {
				let tags = [];
				predictions.forEach(pred => {
					if (pred.results[0].match) {
						tags.push(pred.label);
					}
				});
				if (tags.length > 0) {
					// Suggestions personnalis√©es selon le tag
					let advice = "";
					let icons = {
						insult: "üö´",
						threat: "‚ö†Ô∏è",
						toxicity: "‚ò†Ô∏è",
						severe_toxicity: "üî•",
						identity_attack: "üë§",
						sexual_explicit: "üîû",
						obscene: "ü§¨"
					};
					if (tags.includes("insult")) advice += "Essayez d'utiliser un langage plus respectueux. ";
					if (tags.includes("threat")) advice += "Les menaces ne sont pas tol√©r√©es. ";
					if (tags.includes("toxicity")) advice += "Attention √† la toxicit√© dans vos propos. ";
					if (tags.includes("severe_toxicity")) advice += "Ce message est tr√®s toxique, veuillez le reformuler. ";
					if (tags.includes("identity_attack")) advice += "Respectez l'identit√© des autres. ";
					if (tags.includes("sexual_explicit")) advice += "Le contenu explicite n'est pas appropri√© ici. ";
					if (tags.includes("obscene")) advice += "Le langage obsc√®ne n'est pas autoris√©. ";
					// Affichage visuel am√©lior√© avec classes CSS
					result.innerHTML = `
						<div class="result-toxic">
							<div class="toxic-tags">
								${tags.map(t=>`<span class="toxic-tag">${icons[t]||"‚ùó"} ${t.replace(/_/g,' ')}</span>`).join(' ')}
							</div>
							<div class="toxic-title">Toxicit√© d√©tect√©e !</div>
							<div class="toxic-advice">${advice}</div>
						</div>
					`;
				} else {
					result.innerHTML = `
						<div class="result-safe">
							<span class="safe-message">‚úÖ Aucune toxicit√© d√©tect√©e.</span>
						</div>
					`;
				}
			}).catch(err => {
				console.error("Erreur d'analyse Toxicity:", err);
				result.innerHTML = `
					<div class="result-toxic">
						<div class="toxic-title">Erreur d'analyse</div>
						<div class="toxic-advice">Une erreur s'est produite lors de l'analyse. Veuillez r√©essayer.</div>
					</div>
				`;
			});
		} else {
			result.innerHTML = `
				<div class="result-toxic">
					<div class="toxic-title">Mod√®le non charg√©</div>
					<div class="toxic-advice">Le mod√®le d'analyse n'est pas encore charg√©. Veuillez patienter et r√©essayer.</div>
				</div>
			`;
		}
	});
});
